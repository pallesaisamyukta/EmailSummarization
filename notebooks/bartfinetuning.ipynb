{"cells":[{"cell_type":"markdown","metadata":{},"source":["### Necessary Installations"]},{"cell_type":"markdown","metadata":{},"source":["### Importing the Libraries"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-03-27T00:56:51.486180Z","iopub.status.busy":"2024-03-27T00:56:51.485825Z","iopub.status.idle":"2024-03-27T00:57:02.322202Z","shell.execute_reply":"2024-03-27T00:57:02.321244Z","shell.execute_reply.started":"2024-03-27T00:56:51.486144Z"},"trusted":true},"outputs":[],"source":["import torch\n","import pandas as pd\n","from transformers import BartTokenizer, BartForConditionalGeneration, AdamW, get_linear_schedule_with_warmup\n","from torch.utils.data import Dataset, DataLoader\n","from tqdm.auto import tqdm\n","from datasets import load_metric\n","from sklearn.model_selection import train_test_split\n","import torch.nn as nn\n","from bert_score import score as bert_score\n","from tqdm.auto import tqdm\n","from transformers import logging as hf_logging\n","from random import sample\n","\n","# Set Transformers logger to error only to suppress warnings\n","hf_logging.set_verbosity_error()"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-03-27T00:57:02.324062Z","iopub.status.busy":"2024-03-27T00:57:02.323549Z","iopub.status.idle":"2024-03-27T02:47:47.901842Z","shell.execute_reply":"2024-03-27T02:47:47.900850Z","shell.execute_reply.started":"2024-03-27T00:57:02.324034Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d54448d50b8b427ba73fa74b69ccb225","version_major":2,"version_minor":0},"text/plain":["vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e469ab17efb84ee8b62fc67d196a1925","version_major":2,"version_minor":0},"text/plain":["merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5f8f61b97e4c4151be31730a8dce7650","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"220ee31b67b14ceaad63367c2f5062ab","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/1.72k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Prepared Dataset\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5cae0fef315843debc987c4df2935eef","version_major":2,"version_minor":0},"text/plain":["model.safetensors:   0%|          | 0.00/558M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Evaluating before fine-tuning...\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a8d46c719a5b4f93a47034a8c2c6441f","version_major":2,"version_minor":0},"text/plain":["Downloading builder script:   0%|          | 0.00/2.16k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["Evaluating:   0%|          | 0/272 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3892: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n","  warnings.warn(\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f96ded946d534326a399f8a7db5af56a","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2f5269e95c3a42d68159703ffdd2fdba","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/482 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4ea4d668ebad49939843073eed39a9ac","version_major":2,"version_minor":0},"text/plain":["vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7d3a687996f44fd69548ea1dd599d9cd","version_major":2,"version_minor":0},"text/plain":["merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ad2219fb20a84094bc644aba9c396e36","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f3d5ecb54c844cfca9c19042a51955cf","version_major":2,"version_minor":0},"text/plain":["model.safetensors:   0%|          | 0.00/1.42G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["ROUGE Scores: {'rouge1': 20.182589220382653, 'rouge2': 6.30270462679845, 'rougeL': 13.441462805083676, 'rougeLsum': 13.451910632836627}\n","BERT Scores: {'precision': 0.7851705265045166, 'recall': 0.831574295759201, 'f1': 0.8070542371273041}\n","Epoch 1/5\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6a16aeba845640b6a61b3adb646433f2","version_major":2,"version_minor":0},"text/plain":["Epoch 1/5:   0%|          | 0/2440 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 2/5\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d0bf8d71aa35490c979542b1e35f42b1","version_major":2,"version_minor":0},"text/plain":["Epoch 2/5:   0%|          | 0/2440 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 3/5\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e315b62a7bda484e8e955b12652b778b","version_major":2,"version_minor":0},"text/plain":["Epoch 3/5:   0%|          | 0/2440 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 4/5\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"dc347f6d12ac4de6980584fc953d8bbc","version_major":2,"version_minor":0},"text/plain":["Epoch 4/5:   0%|          | 0/2440 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 5/5\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"62038aa6a40546658c4e0316365c203e","version_major":2,"version_minor":0},"text/plain":["Epoch 5/5:   0%|          | 0/2440 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Evaluating after fine-tuning...\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["Evaluating:   0%|          | 0/272 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["ROUGE Scores: {'rouge1': 44.502404179489844, 'rouge2': 23.63224348670577, 'rougeL': 32.01880399850611, 'rougeLsum': 32.043367763927286}\n","BERT Scores: {'precision': 0.8973617559671402, 'recall': 0.8901673817634582, 'f1': 0.893643033504486}\n","Model evaluation and fine-tuning complete.\n"]}],"source":["# Load dataset from CSV\n","df = pd.read_csv('/kaggle/input/emaildata/merged_email_data.csv')\n","\n","# Custom dataset class\n","class EmailDataset(Dataset):\n","    \"\"\"\n","    A custom PyTorch Dataset for email summarization.\n","\n","    Attributes:\n","        tokenizer (PreTrainedTokenizer): Tokenizer for processing text.\n","        data (DataFrame): DataFrame containing the dataset.\n","        max_length (int): Maximum length of the tokenized input text.\n","        summary_length (int): Maximum length of the tokenized summary text.\n","    \"\"\"\n","    \n","    def __init__(self, tokenizer, data, max_length=512, summary_length=128):\n","        \"\"\"\n","        Initializes the Dataset object with data and configuration.\n","        \"\"\"\n","        \n","        self.tokenizer = tokenizer\n","        self.data = data\n","        self.max_length = max_length\n","        self.summary_length = summary_length\n","\n","    def __len__(self):\n","        \"\"\"Returns the number of items in the dataset.\"\"\"\n","        \n","        return len(self.data)\n","\n","    def __getitem__(self, idx):\n","        \"\"\"\n","        Retrieves an item by its index.\n","\n","        Args:\n","            idx (int): Index of the item to retrieve.\n","\n","        Returns:\n","            A dictionary containing input_ids, attention_mask, and labels for the model.\n","        \"\"\"\n","        \n","        item = self.data.iloc[idx]\n","        thread = item['body'] # Email thread text.\n","        summary = item['summary'] # Summary text.\n","        \n","        # Tokenize the email thread.\n","        model_input = self.tokenizer(thread, max_length=self.max_length, truncation=True, padding='max_length', return_tensors=\"pt\")\n","        \n","        # Tokenize the summary.\n","        with self.tokenizer.as_target_tokenizer():\n","            labels = self.tokenizer(summary, max_length=self.summary_length, truncation=True, padding='max_length', return_tensors=\"pt\")\n","        \n","        model_input[\"labels\"] = labels[\"input_ids\"].squeeze()\n","        \n","        return {key: val.squeeze() for key, val in model_input.items()}\n","\n","# Initialize the tokenizer for BART.\n","tokenizer = BartTokenizer.from_pretrained('facebook/bart-base')\n","\n","# Split dataset into train and validation sets\n","train_df, val_df = train_test_split(df, test_size=0.1, random_state=42)\n","\n","# Initialize the custom Dataset objects for training and validation.\n","train_dataset = EmailDataset(tokenizer, train_df)\n","val_dataset = EmailDataset(tokenizer, val_df)\n","print(\"Prepared Dataset\")\n","\n","# Initialize DataLoader objects for batch processing of training and validation datasets.\n","train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True)  # Increased batch size for faster training\n","val_dataloader = DataLoader(val_dataset, batch_size=8)  # Increased batch size for faster evaluation\n","\n","# Prepare the BART model and move it to the appropriate device (GPU or CPU).\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","bart_model = BartForConditionalGeneration.from_pretrained('facebook/bart-base')\n","bart_model.to(device)\n","\n","# Evaluation function with ROUGE scores\n","def evaluate(model, dataloader, device):\n","    \"\"\"\n","    Evaluates the model on a given dataset using ROUGE and BERTScore metrics.\n","\n","    Args:\n","        model (PreTrainedModel): The model to evaluate.\n","        dataloader (DataLoader): DataLoader providing the dataset for evaluation.\n","        device (torch.device): The device to run the evaluation on.\n","\n","    Returns:\n","        A tuple of dictionaries containing ROUGE scores and BERT scores.\n","    \"\"\"\n","    \n","    rouge = load_metric(\"rouge\")\n","    bert_scores = {\"precision\": [], \"recall\": [], \"f1\": []}  # To store BERTScore\n","    model.eval() # Set the model to evaluation mode.\n","    \n","    progress_bar = tqdm(dataloader, desc=\"Evaluating\", leave=False)\n","    \n","    all_preds = []\n","    all_references = []\n","\n","    for batch in progress_bar:\n","        # Move batch to the specified device.\n","        input_ids = batch['input_ids'].to(device)\n","        attention_mask = batch['attention_mask'].to(device)\n","        labels = batch['labels'].to(device)\n","\n","        with torch.no_grad():\n","            # Generate summaries.\n","            generated_ids = model.generate(input_ids, attention_mask=attention_mask, max_length=128, num_beams=4, early_stopping=True)\n","            preds = [tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=False) for g in generated_ids]\n","            references = [tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=False) for g in labels]\n","            \n","            all_preds.extend(preds)\n","            all_references.extend(references)\n","\n","            # Add predictions and references to ROUGE for batch evaluation.\n","            rouge.add_batch(predictions=preds, references=references)\n","\n","    # BERTScore evaluation on a random subset to manage computation time.\n","    sample_size = 100  # Number of samples to evaluate BERTScore on.\n","    if len(all_preds) > sample_size:\n","        sampled_indices = sample(range(len(all_preds)), sample_size)\n","        sampled_preds = [all_preds[i] for i in sampled_indices]\n","        sampled_references = [all_references[i] for i in sampled_indices]\n","    else:\n","        sampled_preds, sampled_references = all_preds, all_references\n","\n","    # Calculate BERTScore for the sampled predictions and references.\n","    P, R, F1 = bert_score(sampled_preds, sampled_references, lang=\"en\", verbose=False)\n","    bert_scores[\"precision\"].extend(P.tolist())\n","    bert_scores[\"recall\"].extend(R.tolist())\n","    bert_scores[\"f1\"].extend(F1.tolist())\n","\n","    # Calculate average BERT scores.\n","    rouge_result = rouge.compute()\n","    rouge_scores = {key: value.mid.fmeasure * 100 for key, value in rouge_result.items()}\n","\n","    avg_bert_scores = {\n","        \"precision\": sum(bert_scores[\"precision\"]) / len(bert_scores[\"precision\"]),\n","        \"recall\": sum(bert_scores[\"recall\"]) / len(bert_scores[\"recall\"]),\n","        \"f1\": sum(bert_scores[\"f1\"]) / len(bert_scores[\"f1\"]),\n","    }\n","\n","    return rouge_scores, avg_bert_scores\n","\n","\n","# Perform evaluation before fine-tuning to establish a baseline.\n","print(\"Evaluating before fine-tuning...\")\n","before_rouge_scores, before_bert_scores = evaluate(bart_model, val_dataloader, device)\n","print(\"ROUGE Scores:\", before_rouge_scores)\n","print(\"BERT Scores:\", before_bert_scores)\n","\n","\n","# Prepare the optimizer and learning rate scheduler for fine-tuning.\n","optimizer = AdamW(bart_model.parameters(), lr=5e-5)\n","epochs = 5\n","total_steps = len(train_dataloader) * epochs\n","scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n","\n","\n","# Fine-tuning loop.\n","for epoch in range(epochs):\n","    print(f\"Epoch {epoch + 1}/{epochs}\")\n","    bart_model.train() # Set the model to training mode.\n","    for batch in tqdm(train_dataloader, desc=f\"Epoch {epoch + 1}/{epochs}\"):\n","        optimizer.zero_grad() # Clear previous gradients.\n","        \n","        # Move batch to the specified device.\n","        input_ids = batch['input_ids'].to(device)\n","        attention_mask = batch['attention_mask'].to(device)\n","        labels = batch['labels'].to(device)\n","\n","        # Forward pass: compute predictions and loss.\n","        outputs = bart_model(input_ids, attention_mask=attention_mask, labels=labels)\n","        loss = outputs.loss\n","        loss.backward() # Backward pass: compute gradient of the loss with respect to model parameters.\n","        optimizer.step() # Update parameters.\n","        scheduler.step() # Update learning rate schedule.\n","\n","        \n","# Perform evaluation after fine-tuning to see improvements.\n","print(\"Evaluating after fine-tuning...\")\n","after_rouge_scores, after_bert_scores = evaluate(bart_model, val_dataloader, device)\n","print(\"ROUGE Scores:\", after_rouge_scores)\n","print(\"BERT Scores:\", after_bert_scores)\n","\n","print(\"Model evaluation and fine-tuning complete.\")\n","\n","\n","# Save the fine-tuned model\n","torch.save(bart_model.state_dict(), '/kaggle/working/fine-tuned_bart_model.pt')"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":4632740,"sourceId":7890792,"sourceType":"datasetVersion"},{"datasetId":4667235,"sourceId":7938812,"sourceType":"datasetVersion"}],"dockerImageVersionId":30674,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
